% This file was created with JabRef 2.7.2.
% Encoding: MacRoman

@article{pid-goal-functions,
	Author = {Michael Wibral and Viola Priesemann and Jim W. Kay and Joseph T. Lizier and William A. Phillips},
	Title = {Partial Information Decomposition as a Unified Approach to the Specification of Neural Goal Functions},
	Year = {2015},
	Eprint = {arXiv:1510.00831},
	Doi = {10.1016/j.bandc.2015.09.004},
}

@article{brain-cond-inf,
   author="Salvador, R.  and Anguera, M.  and Gomar, J. J.  and Bullmore, E. T.  and Pomarol-Clotet, E. ",
   title="{{C}onditional mutual information maps as descriptors of net connectivity levels in the brain}",
   journal="Front Neuroinform",
   year="2010",
   volume="4",
   pages="115"
}

@article{shannon,
	author = {Shannon, C. E.},
	title = {A Mathematical Theory of Communication},
	journal = {Bell System Technical Journal},
	volume = {27},
	number = {3},
	publisher = {Blackwell Publishing Ltd},
	issn = {1538-7305},
	url = {http://dx.doi.org/10.1002/j.1538-7305.1948.tb01338.x},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	pages = {379--423},
	year = {1948},
}

@book{cover-thomas,
 author = {Cover, Thomas M. and Thomas, Joy A.},
 title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)},
 year = {2006},
 isbn = {0471241954},
 publisher = {Wiley-Interscience},
}

@article{bertschinger,
  author    = {Nils Bertschinger and
               Johannes Rauh and
               Eckehard Olbrich and
               J{\"{u}}rgen Jost and
               Nihat Ay},
  title     = {Quantifying unique information},
  journal   = {CoRR},
  volume    = {abs/1311.2852},
  year      = {2013},
  url       = {http://arxiv.org/abs/1311.2852},
  timestamp = {Tue, 03 Dec 2013 15:04:21 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/BertschingerROJA13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{williams-beer,
  author    = {Paul L. Williams and
               Randall D. Beer},
  title     = {Nonnegative Decomposition of Multivariate Information},
  journal   = {CoRR},
  volume    = {abs/1004.2515},
  year      = {2010},
  url       = {http://arxiv.org/abs/1004.2515},
  timestamp = {Mon, 05 Dec 2011 18:05:19 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1004-2515},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{pid-redundant,
  author    = {Malte Harder and
               Christoph Salge and
               Daniel Polani},
  title     = {A Bivariate Measure of Redundant Information},
  journal   = {CoRR},
  volume    = {abs/1207.2080},
  year      = {2012},
  url       = {http://arxiv.org/abs/1207.2080},
  timestamp = {Wed, 10 Oct 2012 21:28:54 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1207-2080},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{entropy-consciousness,
  author	= {Carhart-Harris, Robin and Leech, Robert and Hellyer, Peter and Shanahan, Murray and Feilding, Amanda and Tagliazucchi, Enzo and Chialvo, Dante and Nutt, David},   
  title		= {The entropic brain: a theory of conscious states informed by neuroimaging research with psychedelic drugs},      
  journal 	= {Frontiers in Human Neuroscience},      
  volume 	= {8},      
  pages		= {20},     
  year		= {2014},      
  url		= {http://journal.frontiersin.org/article/10.3389/fnhum.	2014.00020},
  DOI 		= {10.3389/fnhum.2014.00020},      
  ISSN		= {1662-5161}
}

@misc{pid-synergy,
Author = {Virgil Griffith and Christof Koch},
Title = {Quantifying synergistic mutual information},
Year = {2012},
Eprint = {arXiv:1205.4265},
}

@INPROCEEDINGS{entropy-civil-eng, 
author={L. Peiyu and J. Lijie and W. Yongqing}, 
booktitle={2006 7th International Conference on Computer-Aided Industrial Design and Conceptual Design}, 
title={Application of maximum entropy in engineering structual optimization}, 
year={2006}, 
pages={1-5}, 
keywords={beams (structures);convergence;maximum entropy methods;optimisation;convergence;maximum entropy;structural optimization;Algorithm design and analysis;Constraint optimization;Convergence;Design optimization;Educational institutions;Entropy;Information analysis;Information science;Mathematical model;Optimization methods}, 
doi={10.1109/CAIDCD.2006.329483}, 
month={Nov},}


@article{entropy-finance,
AUTHOR = {Zhou, Rongxi and Cai, Ru and Tong, Guanqun},
TITLE = {Applications of Entropy in Finance: A Review},
JOURNAL = {Entropy},
VOLUME = {15},
YEAR = {2013},
NUMBER = {11},
PAGES = {4909--4931},
URL = {http://www.mdpi.com/1099-4300/15/11/4909},
ISSN = {1099-4300},
ABSTRACT = {Although the concept of entropy is originated from thermodynamics, its concepts and relevant principles, especially the principles of maximum entropy and minimum cross-entropy, have been extensively applied in finance. In this paper, we review the concepts and principles of entropy, as well as their applications in the field of finance, especially in portfolio selection and asset pricing. Furthermore, we review the effects of the applications of entropy and compare them with other traditional and new methods.},
DOI = {10.3390/e15114909}
}

@misc{inf-flow-ising-commentary,
  author = {Lionel Barnett},
  title = {{
A commentary on Information flow in a kinetic Ising model peaks in the disordered phase}},
  howpublished = "\url{http://users.sussex.ac.uk/~lionelb/Ising_TE_commentary.html}",
  year = {2013}, 
  note = "[Online; accessed 06-April-2017]"
}

@book{intro-solid-state-physics,
  Author = {Myers},
  Title = {Introductory Solid State Physics, 2Nd Edition},
  Publisher = {T\&F India},
  Year = {2015},
  ISBN = {0748406603},
  URL = {https://www.amazon.com/Introductory-Solid-State-Physics-2Nd/dp/B01BK0XEJC?SubscriptionId=0JYN1NVW651KCA56C102&tag=techkie-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=B01BK0XEJC}
}

@book{memory-systems-cache-ram,
  Author = {Bruce Jacob and Spencer Ng and David Wang},
  Title = {Memory Systems: Cache, DRAM, Disk},
  Publisher = {Morgan Kaufmann},
  Year = {2010},
  ISBN = {},
  URL = {https://www.amazon.com/Memory-Systems-Cache-DRAM-Disk-ebook/dp/B00BXETR06?SubscriptionId=0JYN1NVW651KCA56C102&tag=techkie-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=B00BXETR06}
}

@book{statistical-mechanics,
  Author = {Kerson Huang},
  Title = {Statistical Mechanics. (Second Edition)},
  Publisher = {John Wiley \& Sons},
  Year = {1987},
  ISBN = {0471815187},
  URL = {https://www.amazon.com/Statistical-Mechanics-Second-Kerson-Huang/dp/B0073M90DQ?SubscriptionId=0JYN1NVW651KCA56C102&tag=techkie-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=B0073M90DQ}
}

@article{ising-history,
 ISSN = {00039519, 14320657},
 URL = {http://www.jstor.org/stable/41134205},
 author = {Martin Niss},
 journal = {Archive for History of Exact Sciences},
 number = {3},
 pages = {267-318},
 publisher = {Springer},
 title = {History of the Lenz-Ising Model 1920-1950: From Ferromagnetic to Cooperative Phenomena},
 volume = {59},
 year = {2005}
}

@article{metropolis,
  added-at = {2010-08-02T15:41:00.000+0200},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  biburl = {https://www.bibsonomy.org/bibtex/25bdc169acdc743b5f9946748d3ce587b/lopusz},
  doi = {10.1063/1.1699114},
  interhash = {b67019ed11f34441c67cc69ee5683945},
  intrahash = {5bdc169acdc743b5f9946748d3ce587b},
  journal = {The Journal of Chemical Physics},
  keywords = {MonteCarlo},
  number = 6,
  pages = {1087-1092},
  publisher = {AIP},
  timestamp = {2010-08-02T15:41:00.000+0200},
  title = {Equation of State Calculations by Fast Computing Machines},
  url = {http://link.aip.org/link/?JCP/21/1087/1},
  volume = 21,
  year = 1953
}

@Article{barnett-ising,
author = "Barnett, L and Lizier, J T and Harr{\'e}, M and Seth, A K and Bossomaier, T",
title = {Information flow in a kinetic Ising model peaks in the disordered phase},
journal = "Phys Rev Lett",
year = "2013",
volume = "111",
number = "17",
pages = "177203-177203",
month = "Oct",
pmid = "24206517",
url = "https://www.ncbi.nlm.nih.gov/pubmed/24206517",
doi = "10.1103/PhysRevLett.111.177203"
}

@INPROCEEDINGS{lizier-rand-bool-nets,
    author = {Joseph T. Lizier and Mikhail Prokopenko and Albert Y. Zomaya},
    title = {The information dynamics of phase transitions in random boolean networks},
    booktitle = {Proceedings of the Eleventh International Conference on the Simulation and Synthesis of Living Systems (ALife XI},
    year = {2008},
    pages = {374--381},
    publisher = {MIT Press}
}

@article{mi-swarms,
  title = {Mutual information as a tool for identifying phase transitions in dynamical complex systems with limited data},
  author = {Wicks, R. T. and Chapman, S. C. and Dendy, R. O.},
  journal = {Phys. Rev. E},
  volume = {75},
  issue = {5},
  pages = {051125},
  numpages = {8},
  year = {2007},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.75.051125},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.75.051125}
}

@article{mi-financial-markets,
  author={M. Harré and T. Bossomaier},
  title={Phase-transition–like behaviour of information measures in financial markets},
  journal={EPL (Europhysics Letters)},
  volume={87},
  number={1},
  pages={18009},
  url={http://stacks.iop.org/0295-5075/87/i=1/a=18009},
  year={2009}
}

@article{mi-ising-analytic,
author="Matsuda, Hiroyuki
and Kudo, Kiyoshi
and Nakamura, Ryoku
and Yamakawa, Osamu
and Murata, Takuo",
title="Mutual information of ising systems",
journal="International Journal of Theoretical Physics",
year="1996",
volume="35",
number="4",
pages="839--845",
abstract="We obtain the mutual information of Ising systems, which shows singular behavior near the critical point. We connect the mutual information with the magnetization and the correlation function. The mutual information is a suitable measure for the critical behavior of Ising systems.",
issn="1572-9575",
doi="10.1007/BF02330576",
url="http://dx.doi.org/10.1007/BF02330576"
}

  	
@article{mi-ising-numeric,
  author={Johannes Wilms and Matthias Troyer and Frank Verstraete},
  title={Mutual information in classical spin models},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2011},
  number={10},
  pages={P10011},
  url={http://stacks.iop.org/1742-5468/2011/i=10/a=P10011},
  year={2011},
  abstract={The total many-body correlations present in finite temperature classical spin systems are studied using the concept of mutual information. As opposed to zero-temperature quantum phase transitions, the total correlations are not maximal at the phase transition, but reach a maximum in the high-temperature paramagnetic phase. The Shannon mutual information and the Renyi mutual information in both Ising and Potts models in two dimensions are calculated numerically by combining matrix product state algorithms and Monte Carlo sampling techniques.}
}
		